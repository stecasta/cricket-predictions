{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q0: Your level of cricket experience\n",
    "Honestly, 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Question 1.\n",
    "Determine the win records (percentage win and total wins) for each team by year and gender,\n",
    "excluding ties, matches with no result, and matches decided by the DLS method in the event that, for whatever\n",
    "reason, the planned innings canâ€™t be completed. Consider only data from 2019. Which male and female teams had\n",
    "the highest win percentages? Which had the highest total wins? Were these teams the same as those with the\n",
    "highest win percentages? Comment on why the leaders of these two stats might differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_json(filename):\n",
    "    with open(filename) as file:\n",
    "        df = json.load(file)\n",
    "\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "def filter_odi_df(df, first_year_to_consider=1800):\n",
    "    \"\"\" Remove matches with no winner or with outcome determined by D/L method. \n",
    "    Optionally filters out matches before a given year. \n",
    "    Returns only relevant columns needed to find win rate.\n",
    "    \"\"\"\n",
    "    df['year'] = pd.to_datetime(df['dates']).dt.year\n",
    "    df = df[df['year'] >= first_year_to_consider]\n",
    "    df = df[(df['outcome.method'] != \"D/L\") & (df['outcome.winner'].notna())]\n",
    "    df = df.drop_duplicates(subset=['matchid', 'year', 'teams'])\n",
    "    return df[['matchid', 'gender', 'outcome.winner', 'teams', 'year']].reset_index(drop=True)\n",
    "\n",
    "def compute_win_rate_table(df):\n",
    "    win_rate = df.groupby(['teams', 'gender', 'year']).apply(\n",
    "        lambda group_df: pd.Series({\n",
    "            'tot_matches': len(group_df),\n",
    "            'win_counts': (group_df['outcome.winner'] == group_df['teams']).sum(),\n",
    "            'win_rate': (group_df['outcome.winner'] == group_df['teams']).mean()\n",
    "        })\n",
    "    )\n",
    "    win_rate = win_rate.sort_values(by=['year', 'win_counts'], ascending=[True, False])\n",
    "\n",
    "    assert all((win_rate['win_rate'] >= 0) & (win_rate['win_rate'] <= 1)), \"Some win rate values are out of the expected range.\"\n",
    "    assert all(win_rate['tot_matches'] >= 0), \"Some total match counts are negative.\"\n",
    "    assert all(win_rate['win_counts'] >= 0), \"Some win counts are negative.\"\n",
    "\n",
    "    return win_rate\n",
    "\n",
    "\n",
    "def get_win_report(win_rate_df, rate=True):\n",
    "    \"\"\"\n",
    "    Get report year by year and aggregate about team performance for male and female.\n",
    "    If rate is set to false, the total wins are used instead of the rate\n",
    "    \"\"\"\n",
    "    col = 'win_rate' if rate else 'win_counts'\n",
    "\n",
    "    # Split the DataFrame into male and female subsets\n",
    "    male_win_rate_df = win_rate_df.xs('male', level='gender')\n",
    "    female_win_rate_df = win_rate_df.xs('female', level='gender')\n",
    "\n",
    "    # Identify teams with most wins per year\n",
    "    male_df_by_year = male_win_rate_df[col].groupby('year').idxmax().apply(lambda x: x[0])\n",
    "    female_df_by_year = female_win_rate_df[col].groupby('year').idxmax().apply(lambda x: x[0])\n",
    "\n",
    "    # Identify team with most wins in aggregate\n",
    "    male_max_wins_agg = male_win_rate_df[col].idxmax()[0]\n",
    "    female_max_wins_agg = female_win_rate_df[col].idxmax()[0]\n",
    "\n",
    "    summary_df = pd.concat([male_df_by_year, female_df_by_year], keys=['Male', 'Female']).rename(f'{col} per year')\n",
    "    display(summary_df)\n",
    "    print(f\"Most {col} from {first_year_to_consider} for males: {male_max_wins_agg}\")\n",
    "    print(f\"Most {col} from {first_year_to_consider} for females: {female_max_wins_agg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_results_path = '../data/match_results.json'\n",
    "first_year_to_consider = 2019\n",
    "\n",
    "odi = load_df_from_json(match_results_path)\n",
    "odi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have two entries for each game, so we have 2153 games in total. One way to handle this would be to combine it into 1 single entry, but I'm not going to do it for now. Also, we don't need most of the columns and some values are only set when a certain event occurs (like outcome.method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique values for some interesting columns\n",
    "for col in ['city', 'gender', 'match_type', 'teams', 'venue', 'outcome.method']:\n",
    "    n_unique = len(odi[col].unique()) \n",
    "    print(f\" Number of unique values for column {col} are: {n_unique}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data about 27 diffrent teams. As expected genders are 2 (male, female) and match_type is only ODI. Let's take a look at the cities to see if they include the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(odi['city'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately they don't. It could have been useful later to determine home and away team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can get an idea about total runs and wickets. Overs seem to be always 50, but as I understood they could be less if all the batters are outed before the end of the innings. Anyway I don't think we will use this info for Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_filt = filter_odi_df(odi, first_year_to_consider=first_year_to_consider)\n",
    "odi_filt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_filt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_filt['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_filt['year'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like in 2020 and 2021 there are way less games. Actually, it makes sense because COVID was there. Let's see if it's actually the case by looking at all the other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check now all the past years to see average games\n",
    "all_years_counts = filter_odi_df(odi, first_year_to_consider=1800)['year'].value_counts()\n",
    "ax = all_years_counts.sort_index().plot(kind='bar', figsize=(12, 6), color='skyblue')\n",
    "plt.axhline(y=all_years_counts.mean(), color='r', linestyle='--', label='Average')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, they are indeed way below average. We can also see there was a positive trend until 2019.\n",
    "From now on we only consider games from 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new table to check total wins and win rate since we are gonna use it multiple times\n",
    "win_rate_df = compute_win_rate_table(odi_filt)\n",
    "win_rate_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these stats we can already see that there is a big difference in the amount of games each team has played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display team with most wins for each year and on aggregate\n",
    "get_win_report(win_rate_df, rate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display team with best win rate for each year and on aggregate\n",
    "get_win_report(win_rate_df, rate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a specific sample to see if statistically relevant\n",
    "team = \"Afghanistan\"\n",
    "year = 2021\n",
    "gender = 'male'\n",
    "print(f\"Total matches played by {team} {gender} team in {year}: {win_rate_df.loc[(team, gender, year), 'tot_matches']}, with a win rate of : {win_rate_df.loc[(team, gender, year), 'win_rate']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to include the total games played in the report, but I'm gonna take a closer look by plotting the data. But from the Afghanistan example we can see that some teams may have 100% rates, but with very few games played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now go into more details by plotting the male data for each year\n",
    "years = win_rate_df.index.get_level_values('year').unique()\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 15))\n",
    "for i, year in enumerate(years):\n",
    "    win_rate_df.xs((year, 'male'), level=('year', 'gender'))['win_counts'][:10].plot(kind='bar', ax=axs[0, i], title=f\"Tot wins - {year}\")\n",
    "    win_rate_df.xs((year, 'male'), level=('year', 'gender'))['win_rate'].sort_values(ascending=False)[:11].plot(kind='bar', ax=axs[1, i], title=f\"Win rate - {year}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it's hard to draw conclusions from these plots alone. Let's check the aggregate for the 3 years, but let's consider the total games played as well now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the aggregate now of most wins with total matches on the side\n",
    "win_rate_df.xs('male', level='gender')[['tot_matches', 'win_counts']].groupby('teams').sum().sort_values('win_counts', ascending=False).plot(kind='bar', figsize=(12, 6), title=f\"Aggregate wins from {first_year_to_consider}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only consider teams with more than 10 games played, we can see that win rate and total wins start to align a bit more. Indeed Australia, India, England and especially New Zeland seem to have performed the best in the last 3 years (let's keep in mind that COVID maybe affected the results).\n",
    "\n",
    "Overall I think that the 2 metrics are not comparable and in a context like this one are both useful. Obviously a team that has played more games has more chances to have a higher number of wins. \n",
    "\n",
    "In general with international games it is a bit trickier to look at stats like this because each year you may be playing different teams which can be more or less strong. In a national league with fixed teams, these metrics are definately more useful. Nevertheless even here they can give a good hint at the overall team performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I tried to track teams performances year by year, but it's a bit challenging given the lack of data for the last 2 years. Nevertheless I think this is a good way to check for trends, especially for regular seasons. For example, if we comfirm that South Africa has played a statistically significant number of games in each 3 years, we could say that they are on a positive trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that 'yearly_win_rate_df' is a DataFrame with teams as index, years as columns, and win rates as values.\n",
    "yearly_win_rate_df = win_rate_df.xs('female', level='gender').groupby(['year', 'teams']).win_rate.mean().unstack()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(yearly_win_rate_df, cmap='YlGnBu', annot=True, fmt=\".1f\")\n",
    "plt.title('Heatmap of Win Rates over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Team')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "Setting aside individual batter production, cricket teams have two main â€˜resourcesâ€™ for producing\n",
    "runs: remaining overs and wickets. The role resources have on run production is central to the statistical method\n",
    "known as â€˜DLSâ€™, which is used to award a winner in the case of incomplete/disrupted matches. Use the ball-by-ball\n",
    "summaries under the innings descriptions of each menâ€™s match to make a dataset with the run and wicket outcomes\n",
    "for each delivery in a match, excluding matches with no result.\n",
    "Develop a model to predict an average teamâ€™s expected runs per over. Please state or include the assump-\n",
    "tions/validation used to justify your model choice. A visualization prior to modelling could be helpful to justify\n",
    "your modelling decisions. Save your intermediate data with team, inning order, remaining overs, and remaining\n",
    "wickets to a JSON/CSV file for Q4. Summarize your conclusions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I should filter out only the men data. Also let's start only with one game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_innings_df_with_match_df(innings, odi):\n",
    "    filtered_match_ids = odi['matchid'].unique()\n",
    "    assert len(filtered_match_ids) == len(odi) / 2\n",
    "    innings = innings[innings['matchid'].isin(filtered_match_ids)]\n",
    "    innings = innings[['matchid', 'innings', 'over', 'runs.total', 'wicket.kind', 'team']]\n",
    "    innings['over_agg'] = innings['over'].apply(lambda x: int(x.split('.')[0]))\n",
    "    innings = innings.drop_duplicates(subset=['matchid', 'innings', 'over', 'team'])\n",
    "    return innings\n",
    "\n",
    "def add_features_to_overs_df(overs, starting_wickets=10, n_overs=50):\n",
    "    overs['wickets_cumul'] = overs.groupby(['matchid', 'innings'])['wickets'].cumsum()\n",
    "    overs['runs_cumul'] = overs.groupby(['matchid', 'innings'])['runs'].cumsum()\n",
    "    overs['remaining_wickets'] = starting_wickets - overs['wickets_cumul']\n",
    "    overs['remaining_overs'] = n_overs - overs['over_agg']\n",
    "\n",
    "    total_runs = overs.groupby(['matchid', 'innings'])['runs'].sum().reset_index()\n",
    "    first_innings_runs = total_runs[total_runs['innings'] == 1]\n",
    "    first_innings_runs = first_innings_runs.rename(columns={'runs': 'first_innings_runs'})\n",
    "    first_innings_runs = first_innings_runs.drop(columns=['innings'])\n",
    "    overs = overs.merge(first_innings_runs, on='matchid', how='left')\n",
    "    # Set to 0 for first innings since no data is available\n",
    "    overs.loc[overs['innings'] == 1, 'first_innings_runs'] = 0\n",
    "    overs['runs_needed_to_par'] = overs['first_innings_runs'] - overs['runs_cumul']\n",
    "    overs.loc[overs['innings'] == 1, 'runs_needed_to_par'] = 0\n",
    "    overs.drop(columns=['first_innings_runs'])\n",
    "\n",
    "    overs['last_5_overs_mean_runs'] = overs['runs'].rolling(window=5).mean()\n",
    "    overs['last_5_overs_mean_runs'].fillna(2, inplace=True)\n",
    "    return overs\n",
    "\n",
    "def shift_resources(df):\n",
    "    df['last_5_overs_mean_runs'] = df['last_5_overs_mean_runs'].shift(1)\n",
    "    df['remaining_wickets'] = df['remaining_wickets'].shift(1)\n",
    "    df['runs_needed_to_par'] = df['runs_needed_to_par'].shift(1)\n",
    "    df['cumulative_runs'] = df['runs_cumul'].shift(1)\n",
    "\n",
    "    # Initialize the first row with 10 for remaining overs and wickets, respectively\n",
    "    df.loc[df.index[0], 'last_5_overs_mean_runs'] = 2\n",
    "    df.loc[df.index[0], 'remaining_wickets'] = 10\n",
    "    df.loc[df.index[0], 'cumulative_runs'] = 0\n",
    "    df.loc[df.index[0], 'runs_needed_to_par'] = df.loc[df.index[0], 'first_innings_runs']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batsman</th>\n",
       "      <th>bowler</th>\n",
       "      <th>non_striker</th>\n",
       "      <th>runs.batsman</th>\n",
       "      <th>runs.extras</th>\n",
       "      <th>runs.total</th>\n",
       "      <th>over</th>\n",
       "      <th>team</th>\n",
       "      <th>innings</th>\n",
       "      <th>matchid</th>\n",
       "      <th>...</th>\n",
       "      <th>replacements.match.in</th>\n",
       "      <th>replacements.match.out</th>\n",
       "      <th>replacements.match.team</th>\n",
       "      <th>replacements.match.reason</th>\n",
       "      <th>replacements.match.in.1</th>\n",
       "      <th>replacements.match.out.1</th>\n",
       "      <th>replacements.match.reason.1</th>\n",
       "      <th>replacements.match.team.1</th>\n",
       "      <th>extras.penalty</th>\n",
       "      <th>extras.wides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA Warner</td>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>TM Head</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>1000887</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA Warner</td>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>TM Head</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>1000887</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA Warner</td>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>TM Head</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>1000887</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batsman         bowler non_striker  runs.batsman  runs.extras  \\\n",
       "0  DA Warner  Mohammad Amir     TM Head             0            0   \n",
       "1  DA Warner  Mohammad Amir     TM Head             0            0   \n",
       "2  DA Warner  Mohammad Amir     TM Head             0            0   \n",
       "\n",
       "   runs.total over       team  innings  matchid  ...  replacements.match.in  \\\n",
       "0           0  0.1  Australia        1  1000887  ...                    NaN   \n",
       "1           0  0.2  Australia        1  1000887  ...                    NaN   \n",
       "2           0  0.3  Australia        1  1000887  ...                    NaN   \n",
       "\n",
       "  replacements.match.out replacements.match.team replacements.match.reason  \\\n",
       "0                    NaN                     NaN                       NaN   \n",
       "1                    NaN                     NaN                       NaN   \n",
       "2                    NaN                     NaN                       NaN   \n",
       "\n",
       "   replacements.match.in.1  replacements.match.out.1  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                      NaN                       NaN   \n",
       "\n",
       "   replacements.match.reason.1  replacements.match.team.1 extras.penalty  \\\n",
       "0                          NaN                        NaN            NaN   \n",
       "1                          NaN                        NaN            NaN   \n",
       "2                          NaN                        NaN            NaN   \n",
       "\n",
       "  extras.wides  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_results_path = '../data/match_results.json'\n",
    "innings_results_path = '../data/innings_results.json'\n",
    "\n",
    "odi = load_df_from_json(match_results_path)\n",
    "innings = load_df_from_json(innings_results_path)\n",
    "\n",
    "innings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique values for some interesting columns\n",
    "for col in ['batsman', 'bowler', 'non_striker', 'team', 'wicket.kind']:\n",
    "    n_unique = len(innings[col].unique()) \n",
    "    print(f\" Number of unique values for column {col} are: {n_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(innings['wicket.kind'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_filt = filter_odi_df(odi, first_year_to_consider=1800)\n",
    "innings_filt = filter_innings_df_with_match_df(innings, odi_filt)\n",
    "innings_filt.tail(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_filt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_filt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchid</th>\n",
       "      <th>innings</th>\n",
       "      <th>over_agg</th>\n",
       "      <th>team</th>\n",
       "      <th>runs</th>\n",
       "      <th>wickets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168673</th>\n",
       "      <td>997995</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168674</th>\n",
       "      <td>997995</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168675</th>\n",
       "      <td>997995</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168676</th>\n",
       "      <td>997995</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168677</th>\n",
       "      <td>997995</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       matchid  innings  over_agg      team  runs  wickets\n",
       "168673  997995        2        43  Scotland     4        0\n",
       "168674  997995        2        44  Scotland     2        1\n",
       "168675  997995        2        45  Scotland     9        0\n",
       "168676  997995        2        46  Scotland     7        0\n",
       "168677  997995        2        47  Scotland     4        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overs = innings_filt.groupby(['matchid', 'innings', 'over_agg', 'team']).agg(\n",
    "    runs=('runs.total', 'sum'),\n",
    "    wickets=('wicket.kind', 'count')\n",
    ").reset_index()\n",
    "\n",
    "overs.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchid</th>\n",
       "      <th>innings</th>\n",
       "      <th>level_2</th>\n",
       "      <th>over_agg</th>\n",
       "      <th>team</th>\n",
       "      <th>runs</th>\n",
       "      <th>wickets</th>\n",
       "      <th>wickets_cumul</th>\n",
       "      <th>runs_cumul</th>\n",
       "      <th>remaining_wickets</th>\n",
       "      <th>remaining_overs</th>\n",
       "      <th>first_innings_runs</th>\n",
       "      <th>runs_needed_to_par</th>\n",
       "      <th>last_5_overs_mean_runs</th>\n",
       "      <th>cumulative_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000887</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000887</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000887</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000887</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchid  innings  level_2  over_agg       team  runs  wickets  \\\n",
       "0  1000887        1        0         0  Australia     1        0   \n",
       "1  1000887        1        1         1  Australia     1        0   \n",
       "2  1000887        1        2         2  Australia     3        0   \n",
       "3  1000887        1        3         3  Australia     6        0   \n",
       "4  1000887        1        4         4  Australia     2        2   \n",
       "\n",
       "   wickets_cumul  runs_cumul  remaining_wickets  remaining_overs  \\\n",
       "0              0           1               10.0               50   \n",
       "1              0           2               10.0               49   \n",
       "2              0           5               10.0               48   \n",
       "3              0          11               10.0               47   \n",
       "4              2          13               10.0               46   \n",
       "\n",
       "   first_innings_runs  runs_needed_to_par  last_5_overs_mean_runs  \\\n",
       "0                   0                 0.0                     2.0   \n",
       "1                   0                 0.0                     2.0   \n",
       "2                   0                 0.0                     2.0   \n",
       "3                   0                 0.0                     2.0   \n",
       "4                   0                 0.0                     2.0   \n",
       "\n",
       "   cumulative_runs  \n",
       "0              0.0  \n",
       "1              1.0  \n",
       "2              2.0  \n",
       "3              5.0  \n",
       "4             11.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overs_ds = add_features_to_overs_df(overs)\n",
    "# Shift features so we don't leak the future into the data\n",
    "overs_ds = overs_ds.groupby(['matchid', 'innings']).apply(shift_resources)\n",
    "# Unpack groups to process it more easily\n",
    "overs_ds = overs_ds.drop(columns=[\"matchid\", \"innings\"]).reset_index()\n",
    "overs_ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168678 entries, 0 to 168677\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   matchid                 168678 non-null  object \n",
      " 1   innings                 168678 non-null  int64  \n",
      " 2   level_2                 168678 non-null  int64  \n",
      " 3   over_agg                168678 non-null  int64  \n",
      " 4   team                    168678 non-null  object \n",
      " 5   runs                    168678 non-null  int64  \n",
      " 6   wickets                 168678 non-null  int64  \n",
      " 7   wickets_cumul           168678 non-null  int64  \n",
      " 8   runs_cumul              168678 non-null  int64  \n",
      " 9   remaining_wickets       168678 non-null  float64\n",
      " 10  remaining_overs         168678 non-null  int64  \n",
      " 11  first_innings_runs      168678 non-null  int64  \n",
      " 12  runs_needed_to_par      168678 non-null  float64\n",
      " 13  last_5_overs_mean_runs  168678 non-null  float64\n",
      " 14  cumulative_runs         168678 non-null  float64\n",
      "dtypes: float64(4), int64(9), object(2)\n",
      "memory usage: 19.3+ MB\n"
     ]
    }
   ],
   "source": [
    "overs_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overs_ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchid</th>\n",
       "      <th>innings</th>\n",
       "      <th>level_2</th>\n",
       "      <th>over_agg</th>\n",
       "      <th>team</th>\n",
       "      <th>runs</th>\n",
       "      <th>wickets</th>\n",
       "      <th>wickets_cumul</th>\n",
       "      <th>runs_cumul</th>\n",
       "      <th>remaining_wickets</th>\n",
       "      <th>remaining_overs</th>\n",
       "      <th>first_innings_runs</th>\n",
       "      <th>runs_needed_to_par</th>\n",
       "      <th>last_5_overs_mean_runs</th>\n",
       "      <th>cumulative_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [matchid, innings, level_2, over_agg, team, runs, wickets, wickets_cumul, runs_cumul, remaining_wickets, remaining_overs, first_innings_runs, runs_needed_to_par, last_5_overs_mean_runs, cumulative_runs]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will return all the rows where cumulative wickets are greater than 10\n",
    "anomalies = overs_ds[overs_ds['runs_needed_to_par'] < 0]\n",
    "print(len(anomalies))\n",
    "display(anomalies)\n",
    "# anomaly_details = overs_ds[(overs_ds['matchid'].isin(anomalies['matchid'])) & \n",
    "#                              (overs['innings'].isin(anomalies['innings']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it's only one case we can just modify it with a reasonable value (would need better handling though)\n",
    "overs_ds[overs_ds['runs_needed_to_par'] < 0] = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert overs_ds['runs'].between(0, 36).all()\n",
    "assert overs_ds['remaining_wickets'].between(0, 10).all()\n",
    "assert overs_ds['remaining_overs'].between(0, 50).all()\n",
    "assert overs_ds['wickets'].between(0,6).all()\n",
    "assert overs_ds['runs_needed_to_par'].between(0,1000*50*6*6).all()\n",
    "assert overs_ds.isnull().sum().all() == 0\n",
    "assert overs_ds.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overs[[\n",
    "                    \"remaining_overs\",\n",
    "                    \"remaining_wickets\",\n",
    "                    \"innings\",\n",
    "                    \"cumulative_runs\",\n",
    "                    \"runs_needed_to_par\",\n",
    "                    \"last_5_overs_mean_runs\",\n",
    "]].to_csv('../data/intermediate_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the match results data\n",
    "with open('../data/match_results.json') as file:\n",
    "    match_results = json.load(file)\n",
    "\n",
    "match_results_df = pd.DataFrame(match_results)\n",
    "\n",
    "# Rename 'teams' column in match_results_df to 'team' for consistency\n",
    "match_results_df = match_results_df.rename(columns={'teams': 'team'})\n",
    "match_results_df = match_results_df[match_results_df['outcome.method'] != \"D/L\"]\n",
    "\n",
    "# Load the ball-by-ball innings data\n",
    "with open('../data/innings_results.json') as file:\n",
    "    innings_data = json.load(file)\n",
    "\n",
    "innings_df = pd.DataFrame(innings_data)\n",
    "\n",
    "# Remove matches with no result\n",
    "match_results_df = match_results_df[match_results_df['outcome.winner'].notna()]\n",
    "\n",
    "# Get matchids of matches with result\n",
    "match_ids_with_result = match_results_df['matchid'].unique()\n",
    "\n",
    "# Filter innings_df to include only matchids of matches with result\n",
    "innings_df = innings_df[innings_df['matchid'].isin(match_ids_with_result)]\n",
    "\n",
    "# Merge the gender field from match_results_df to innings_df\n",
    "innings_df = innings_df.merge(match_results_df[['matchid', 'team', 'gender', 'dates']], on=['matchid', 'team'], how='left')\n",
    "\n",
    "# Filter for male matches\n",
    "innings_df = innings_df[innings_df['gender'] == 'male']\n",
    "\n",
    "# Convert the 'dates' column to datetime format\n",
    "innings_df['dates'] = pd.to_datetime(innings_df['dates'])\n",
    "\n",
    "# Filter out matches before 2019\n",
    "# innings_df = innings_df[innings_df['dates'].dt.year == 2020]\n",
    "\n",
    "# Keep only necessary columns \n",
    "innings_df = innings_df[['matchid', 'innings', 'over', 'runs.total', 'wicket.kind', 'team']]\n",
    "innings_df = innings_df.drop_duplicates(subset=['matchid', 'innings', 'over', 'team'])\n",
    "# innings_df = innings_df[innings_df['innings'] == 1]\n",
    "\n",
    "# Compute wickets and cumulative wickets directly in innings_df\n",
    "innings_df['wickets'] = innings_df['wicket.kind'].notnull()\n",
    "innings_df['wickets_cumul'] = innings_df.groupby(['matchid', 'innings', 'team'])['wickets'].cumsum()\n",
    "innings_df['runs_cumul'] = innings_df.groupby(['matchid', 'innings', 'team'])['runs.total'].cumsum()\n",
    "assert innings_df['wickets_cumul'].between(0,10).all()\n",
    "# Compute remaining wickets and remaining overs\n",
    "innings_df['over'] = innings_df['over'].apply(lambda x: int(x.split('.')[0]) if int(x.split('.')[1]) == 6 else float(x)).astype(int)\n",
    "innings_df['remaining_wickets'] = 10 - innings_df['wickets_cumul']\n",
    "innings_df['remaining_overs'] = 50 - innings_df['over']\n",
    "\n",
    "# Calculate total runs per match per innings\n",
    "total_runs = innings_df.groupby(['matchid', 'innings'])['runs.total'].sum().reset_index()\n",
    "\n",
    "# Filter to keep only the first innings\n",
    "first_innings_runs = total_runs[total_runs['innings'] == 1]\n",
    "\n",
    "# Rename columns for merging\n",
    "first_innings_runs = first_innings_runs.rename(columns={'runs.total': 'first_innings_runs'})\n",
    "first_innings_runs = first_innings_runs.drop(columns=['innings'])\n",
    "\n",
    "# Merge first_innings_runs into the main dataframe\n",
    "innings_df = innings_df.merge(first_innings_runs, on='matchid', how='left')\n",
    "\n",
    "# Forward fill the NaNs to propagate the first_innings_runs to the second innings\n",
    "innings_df['first_innings_runs'] = innings_df.groupby('matchid')['first_innings_runs'].ffill()\n",
    "\n",
    "# At this point, the 'first_innings_runs' column for the first innings will be its own score, \n",
    "# which is not what we want. We set 'first_innings_runs' to NaN for the first innings:\n",
    "print(innings_df.columns)\n",
    "innings_df.loc[innings_df['innings'] == 1, 'first_innings_runs'] = 0\n",
    "innings_df['runs_needed_to_par'] = innings_df['first_innings_runs'] - innings_df['runs_cumul']\n",
    "innings_df.loc[innings_df['innings'] == 1, 'runs_needed_to_par'] = 0\n",
    "#  Display the dataframe\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "#     display(innings_df)\n",
    "\n",
    "grouped_df = innings_df.groupby(['matchid', 'innings', 'team', 'over']).agg(\n",
    "    runs=('runs.total', 'sum'),\n",
    "    wickets=('wickets', 'sum'),  \n",
    "    remaining_wickets=('remaining_wickets', 'min'),  # minimum remaining wickets in the over\n",
    "    remaining_overs=('remaining_overs', 'min'),  # minimum remaining overs in the over\n",
    "    cumulative_runs=('runs_cumul', 'max'),  # minimum remaining overs in the over\n",
    "    first_innings_runs=('first_innings_runs', 'max'),\n",
    "    runs_needed_to_par=('runs_needed_to_par', 'min')\n",
    ").reset_index()\n",
    "grouped_df = grouped_df.groupby(['matchid', 'innings']).apply(shift_resources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[[\n",
    "                    \"remaining_overs\",\n",
    "                    \"remaining_wickets\",\n",
    "                    \"innings\",\n",
    "                    \"cumulative_runs\",\n",
    "                    \"runs_needed_to_par\",\n",
    "                    \"last_5_overs_mean_runs\",\n",
    "]].to_csv('../data/intermediate_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "#     display(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "    display(grouped_df[grouped_df['matchid']==\"1153846\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return all the rows where cumulative wickets are greater than 10\n",
    "anomalies = grouped_df[grouped_df['runs_needed_to_par'] < 0]\n",
    "grouped_df[grouped_df['runs_needed_to_par'] < 0] = 3\n",
    "print(len(grouped_df))\n",
    "# Display these instances\n",
    "print(len(anomalies))\n",
    "display(anomalies)\n",
    "anomaly_details = innings_df[(innings_df['matchid'].isin(anomalies['matchid'])) & \n",
    "                             (innings_df['innings'].isin(anomalies['innings']))]\n",
    "print(anomaly_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert grouped_df['runs'].between(0, 36).all()\n",
    "assert grouped_df['remaining_wickets'].between(0, 10).all()\n",
    "assert grouped_df['remaining_overs'].between(0, 50).all()\n",
    "assert innings_df['wickets'].between(0,6).all()\n",
    "print(min(grouped_df['runs_needed_to_par']), max(grouped_df['runs_needed_to_par']))\n",
    "assert grouped_df['runs_needed_to_par'].between(0,1000*50*6*6).all()\n",
    "assert grouped_df.isnull().sum().all() == 0\n",
    "assert grouped_df.duplicated().sum() == 0\n",
    "# groupd_df = grouped_df[['over', 'remaining_overs', 'remaining_wickets', 'runs']]\n",
    "# assert (grouped_df.sort_values(['matchid', 'innings', 'over'])['remaining_overs'].diff().dropna() <= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 148436 entries, ('1000887', 1, 0) to ('997995', 2, 148435)\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   matchid                 148436 non-null  object \n",
      " 1   innings                 148436 non-null  int64  \n",
      " 2   team                    148436 non-null  object \n",
      " 3   over                    148436 non-null  int32  \n",
      " 4   runs                    148436 non-null  int64  \n",
      " 5   wickets                 148436 non-null  int64  \n",
      " 6   remaining_wickets       148436 non-null  float64\n",
      " 7   remaining_overs         148436 non-null  int32  \n",
      " 8   cumulative_runs         148436 non-null  float64\n",
      " 9   first_innings_runs      148436 non-null  int64  \n",
      " 10  runs_needed_to_par      148436 non-null  float64\n",
      " 11  last_5_overs_mean_runs  148436 non-null  float64\n",
      "dtypes: float64(4), int32(2), int64(4), object(2)\n",
      "memory usage: 18.7+ MB\n"
     ]
    }
   ],
   "source": [
    "grouped_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the percentage of remaining resources\n",
    "grouped_df['percentage_of_combined_resources'] = (grouped_df['remaining_wickets'] / 10 + grouped_df['remaining_overs'] / 50) / 2 * 100\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a line plot for each value of remaining wickets\n",
    "for wickets in grouped_df['remaining_wickets'].unique():\n",
    "    subset_df = grouped_df[grouped_df['remaining_wickets'] == wickets]\n",
    "    sns.lineplot(x='remaining_overs', y='percentage_of_combined_resources', data=subset_df, label=f'Remaining wickets: {wickets}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Percentage of Combined Resources')\n",
    "plt.title('Remaining Resources vs Remaining Overs for Different Numbers of Wickets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Remaining overs vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 2. Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_wickets\", y=\"runs\")\n",
    "plt.title('Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Remaining overs and Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\", hue=\"remaining_wickets\", palette=\"viridis\")\n",
    "plt.title('Remaining Overs and Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.legend(title='Remaining Wickets')\n",
    "plt.show()\n",
    "\n",
    "# 4. Percentage of combined resources vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"percentage_of_combined_resources\", y=\"runs\")\n",
    "plt.title('Percentage of Combined Resources vs Runs')\n",
    "plt.xlabel('Percentage of Combined Resources')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots\n",
    "\n",
    "# 1. Remaining overs vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 2. Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_wickets\", y=\"runs\")\n",
    "plt.title('Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Remaining overs and Remaining wickets vs Runs\n",
    "# For this, we will make a heatmap\n",
    "pivot_table = grouped_df.pivot_table(index='remaining_overs', columns='remaining_wickets', values='runs', aggfunc='mean')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_table, cmap='viridis')\n",
    "plt.title('Remaining Overs and Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Remaining Overs')\n",
    "plt.show()\n",
    "\n",
    "# 4. Percentage of combined resources vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"percentage_of_combined_resources\", y=\"runs\")\n",
    "plt.title('Percentage of Combined Resources vs Runs')\n",
    "plt.xlabel('Percentage of Combined Resources')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. Line plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 1. Line plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"remaining_wickets\")\n",
    "plt.title('Remaining Overs vs remaining wickets')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('wickets')\n",
    "plt.show()\n",
    "\n",
    "# 2. Box plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"runs\")\n",
    "plt.title('Distribution of Runs')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"wickets\")\n",
    "plt.title('Distribution of wickets')\n",
    "plt.xlabel('Wickets')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_wickets\")\n",
    "plt.title('Distribution of remaining wickets')\n",
    "plt.xlabel('remaining wickets')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_overs\")\n",
    "plt.title('Distribution of remaining overs')\n",
    "plt.xlabel('remaining overs')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 4. Heatmaps\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap_data = grouped_df.pivot_table(index='remaining_wickets', columns='remaining_overs', values='runs', aggfunc='mean')\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\")\n",
    "plt.title('Runs by Remaining Overs and Wickets')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Remaining Wickets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram for runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"runs\", bins=30, kde=True)\n",
    "plt.title('Distribution of Runs')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for remaining overs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_overs\", bins=30, kde=True)\n",
    "plt.title('Distribution of Remaining Overs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for remaining wickets\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_wickets\", bins=10, kde=True)\n",
    "plt.title('Distribution of Remaining Wickets')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(np.array(y_pred - y * grouped_df[\"runs\"].max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= np.array([10, 50])\n",
    "print(max(X[:,0]))\n",
    "print(max(X[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "RMSE train: 3.359581080332122\n",
      "RMSE test: 3.3309633799330873\n",
      "R2 score test: 0.10468450969210452\n",
      "--------------------------\n",
      "Model: XGBoost\n",
      "RMSE train: 3.073399112840215\n",
      "RMSE test: 3.6254357939570765\n",
      "R2 score test: -0.06061268902084427\n",
      "--------------------------\n",
      "Model: Random Forest\n",
      "RMSE train: 1.6206600306266035\n",
      "RMSE test: 3.5272099269203823\n",
      "R2 score test: -0.003919750548120993\n",
      "--------------------------\n",
      "Model: MLP\n",
      "RMSE train: 3.317614470237227\n",
      "RMSE test: 3.2959531152875208\n",
      "R2 score test: 0.12340612314129107\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "X = np.sqrt(np.array(overs_ds[[\"remaining_overs\", \"remaining_wickets\", \"innings\", \"cumulative_runs\", \"runs_needed_to_par\", \"last_5_overs_mean_runs\"]]))\n",
    "# X = np.sqrt(np.array(grouped_df[[\"remaining_overs\"]]))\n",
    "y = np.array(overs_ds[\"runs\"])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(objective ='reg:squarederror', n_estimators=100, max_depth=7, eta=1, subsample=0.7, colsample_bytree=0.8),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(50, 10), learning_rate_init=0.01, max_iter=1000, random_state=1)\n",
    "}\n",
    "\n",
    "# Loop through the models and train and evaluate each one\n",
    "for model_name, model in models.items():\n",
    "    # Create the pipeline: preprocessor + model\n",
    "    # pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "    #                        ('model', model)])   # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_val = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train) \n",
    "    mse_test = mean_squared_error(y_test, y_pred_val)\n",
    "    r2 = r2_score(y_test, y_pred_val)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"RMSE train: {np.sqrt(mse_train)}\")\n",
    "    print(f\"RMSE test: {np.sqrt(mse_test)}\")\n",
    "    print(f\"R2 score test: {r2}\")\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(models[\"MLP\"], \"../models/cricket_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. \n",
    "More generally and unrelated to cricket or the previous questions, model deployment in a production\n",
    "environment is an important aspect of an engineerâ€™s toolkit. Describe a scalable architecture (a diagram may\n",
    "be helpful) that would be appropriate for deploying a model that predicts frame-level play values into a cloud\n",
    "environment with the following assumptions:\n",
    "â€¢ Spatial temporal high frame-rate data (~1 GB per game)\n",
    "â€¢ Play-values are predicted at each frame of a game\n",
    "â€¢ Delivery of game predictions are expected to be delivered overnight\n",
    "â€¢ 500 games per season with 50 games a day\n",
    "â€¢ 5 seasons of existing data\n",
    "â€¢ Model training resources:\n",
    "â€“ 8 hour runtime with multiple cores (8) and large memory usage\n",
    "â€¢ Model prediction resources:\n",
    "â€“ 60 min runtime per game with a single CPU and 4 GB of memory usage\n",
    "List out the services, tooling, and reasoning for the choices of architecture. For example, a LAMP stack could be\n",
    "appropriate for an internal home network webpage on a Raspberry Pi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the diagram below.\n",
    "\n",
    "Although the question is focused on deployment, I decided to include development as well because I think that you can only have a solid production environment if you set up the dev one properly. \n",
    "\n",
    "I propose to use AWS services because they are the ones I'm most familiar with, but any cloud provider would do. Also for simplicity I'm not going to delve into security details.\n",
    "\n",
    "Overall, I would use Kubeflow to orchestrate tasks, keep track of experiments/models and serve in production. Kubeflow is a workflow management system optimized for machine learning. It runs on kubernetes and it can be integrated into the AWS environment with EKS.\n",
    "\n",
    "First of all, I would make two accounts, one for development and one for production, so that it is easier to separate costs and also makes it harder for developers to accidentaly modify production setup by limiting its access. Depending on the people available in the team, we could set up also a staging account (with the same architecture as the prod environment), for testing before real deployment.\n",
    "\n",
    "We can store previous seasons data on a S3 bucket. Since the total data available is around 2.5 TB, and we don't expect exponential increase in the near future, this will suffice. If needed, we can also add an RDS instance to store structured data like game metadata.\n",
    "\n",
    "Developers can access the data with containerized Jupyter notebooks, ensuring high reproducibility. Each experiment is tracked with kubeflow (integration of other tools like w&b also possible) and the models + training artifacts are stored in a S3 bucket.\n",
    "\n",
    "When the developers set a new model as baseline, they can define a Kubeflow pipeline to automate model training. This includes retrieving the data, preprocessing and doing the actual training on a AWS machine with GPU. Each step of the pipeline runs in a container that a developer previously pushed to a container registry. This approach ensures reproducibility.\n",
    "\n",
    "On the production side, we also have a Kubeflow cluster. As soon as the game data is ready (this could be triggered by an API call or an event) a lambda function is run and it launches the inference of the model.  Ideally, the data is already available on an S3 bucket in the production account. We can then store results and metadata in an RDS SQL database and potentially transfer the data to the dev account for future retraining. By using Kubernetes, we can adjust the number of active nodes based on the number of concurrent requests, making this architecture inherently scalable.\n",
    "\n",
    "Registration of containers to the registry as well as model deployment and testing can be automated with CI/CD linked to pull requests in the git repository.\n",
    "\n",
    "In terms of costs, for the storage of past games we would spend either 405$ or 121$ depending on the urgency of retrainings (instant retrieval for the former and up to 12hrs for the latter). Given that we can shut down nodes when we don't use time, inference time in a year is 500 hours. We can further reduce costs by choosing spot instances since we don't need to operate in real time. We can then choose an instance like a m6g.medium, with 4GiB of memory and a single core. This will give a yearly cost of 17.75$. \n",
    "For training the model the choice will depend if we need access to machines with GPUs. Since we are dealing with videos, this is very likely. We can then choose a g3s.xlarge with 8Gb of vRAM and 4 CPUs, coming at a hourly cost of 0.225$ for spot intances. If we consider 1 retraining per week during the season (~32), the cost is 32x8x0.225=57.6$\n",
    "\n",
    "Summing it up, considering periodic retraining, the main fixed cost for this architecture is around 195$ per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../images/architecture-diagram.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "Question 4. Save your model from Q2 into a file and create a packaged solution for being able to build, deploy\n",
    "and run your model locally. We are expecting a solution where local runs can be initiated from the command line,\n",
    "not an API-style deployment. As a way to test your package, create a shell script that takes data saved from Q2,\n",
    "filters for the first 5 Ireland overs, sends them to your model, and displays the model results to stdout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to run the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cricket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
