{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q0: Your level of cricket experience\n",
    "Honestly, 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Question 1.\n",
    "Determine the win records (percentage win and total wins) for each team by year and gender,\n",
    "excluding ties, matches with no result, and matches decided by the DLS method in the event that, for whatever\n",
    "reason, the planned innings can’t be completed. Consider only data from 2019. Which male and female teams had\n",
    "the highest win percentages? Which had the highest total wins? Were these teams the same as those with the\n",
    "highest win percentages? Comment on why the leaders of these two stats might differ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we work only with the match result data. We just want to know the win records and who has the highest. Let's explore the data first. Get out some stats. I have to decide wether I wanna use pandas or flask or spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "import os\n",
    "\n",
    "# Load the match results data\n",
    "with open('../data/match_results.json') as file:\n",
    "    match_results = json.load(file)\n",
    "\n",
    "# Convert the data to pandas DataFrames\n",
    "match_results_df = pd.DataFrame(match_results)\n",
    "n_entries = len(match_results_df)\n",
    "match_results_df = match_results_df.dropna(thresh=0.01*n_entries, axis=1)\n",
    "\n",
    "# List of columns to keep\n",
    "cols_to_keep = ['dates', 'gender', 'outcome.winner', \n",
    "                'teams', 'outcome.method']\n",
    "\n",
    "# Get the list of all columns\n",
    "all_cols = match_results_df.columns\n",
    "\n",
    "# Get the list of columns to drop\n",
    "cols_to_drop = all_cols.difference(cols_to_keep)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "match_results_df = match_results_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Number of attributes: \", len(match_results_df.keys()))\n",
    "print(match_results_df.keys())\n",
    "print(\"Number of entries: \", len(match_results_df))\n",
    "print(match_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'dates' to datetime and extract the year\n",
    "match_results_df['year'] = pd.to_datetime(match_results_df['dates']).dt.year\n",
    "\n",
    "# Filter for D/L method and count the games per year and team\n",
    "dl_counts_per_year = match_results_df[match_results_df['outcome.method'] == \"D/L\"].groupby(['year', 'teams']).size()\n",
    "\n",
    "print(dl_counts_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out matches before 2019\n",
    "# Convert the 'dates' column to datetime format\n",
    "match_results_df['dates'] = pd.to_datetime(match_results_df['dates'])\n",
    "\n",
    "# Filter out matches before 2019\n",
    "match_results_df = match_results_df[match_results_df['dates'].dt.year == 2020]\n",
    "match_results_df = match_results_df[match_results_df['gender'] == 'male']\n",
    "\n",
    "print(\"Number of entries: \", len(match_results_df))\n",
    "print(match_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_counts_no_dl = match_results_df[(match_results_df['outcome.winner'] == match_results_df['teams']) & \n",
    "                                    (match_results_df['outcome.method'] != 'D/L')]['teams'].value_counts()\n",
    "\n",
    "print(win_counts_no_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total games per team\n",
    "total_games_no_dl = match_results_df[(match_results_df['outcome.method'] != 'D/L')]['teams'].value_counts()\n",
    "\n",
    "# Calculate win percentage\n",
    "win_percentage_no_dl = (win_counts_no_dl / total_games_no_dl) * 100\n",
    "\n",
    "print(win_percentage_no_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate win counts excluding D/L method and ties\n",
    "win_counts_no_dl_no_tie = match_results_df[(match_results_df['outcome.winner'] == match_results_df['teams']) & \n",
    "                                           (match_results_df['outcome.method'] != 'D/L') &\n",
    "                                           (match_results_df['outcome.winner'].notna())]['teams'].value_counts()\n",
    "\n",
    "# Calculate total games per team excluding ties\n",
    "total_games_no_dl_no_tie = match_results_df[(match_results_df['outcome.method'] != 'D/L') & \n",
    "                                            (match_results_df['outcome.winner'].notna())]['teams'].value_counts()\n",
    "\n",
    "# Calculate win percentage\n",
    "win_percentage_no_dl_no_tie = (win_counts_no_dl_no_tie / total_games_no_dl_no_tie) * 100\n",
    "\n",
    "print(win_percentage_no_dl_no_tie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "Setting aside individual batter production, cricket teams have two main ‘resources’ for producing\n",
    "runs: remaining overs and wickets. The role resources have on run production is central to the statistical method\n",
    "known as ‘DLS’, which is used to award a winner in the case of incomplete/disrupted matches. Use the ball-by-ball\n",
    "summaries under the innings descriptions of each men’s match to make a dataset with the run and wicket outcomes\n",
    "for each delivery in a match, excluding matches with no result.\n",
    "Develop a model to predict an average team’s expected runs per over. Please state or include the assump-\n",
    "tions/validation used to justify your model choice. A visualization prior to modelling could be helpful to justify\n",
    "your modelling decisions. Save your intermediate data with team, inning order, remaining overs, and remaining\n",
    "wickets to a JSON/CSV file for Q4. Summarize your conclusions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I should filter out only the men data. Also let's start only with one game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_resources(df):\n",
    "    df['last_5_overs_mean_runs'] = df['runs'].rolling(window=5).mean()\n",
    "    df['last_5_overs_mean_runs'].fillna(2, inplace=True)\n",
    "\n",
    "    df['last_5_overs_mean_runs'] = df['last_5_overs_mean_runs'].shift(1)\n",
    "    df['remaining_wickets'] = df['remaining_wickets'].shift(1)\n",
    "    df['runs_needed_to_par'] = df['runs_needed_to_par'].shift(1)\n",
    "    df['cumulative_runs'] = df['cumulative_runs'].shift(1)\n",
    "\n",
    "    # Initialize the first row with 10 for remaining overs and wickets, respectively\n",
    "    df.loc[df.index[0], 'last_5_overs_mean_runs'] = 2\n",
    "    df.loc[df.index[0], 'remaining_wickets'] = 10\n",
    "    df.loc[df.index[0], 'cumulative_runs'] = 0\n",
    "    df.loc[df.index[0], 'runs_needed_to_par'] = df.loc[df.index[0], 'first_innings_runs']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the match results data\n",
    "with open('../data/match_results.json') as file:\n",
    "    match_results = json.load(file)\n",
    "\n",
    "match_results_df = pd.DataFrame(match_results)\n",
    "\n",
    "# Rename 'teams' column in match_results_df to 'team' for consistency\n",
    "match_results_df = match_results_df.rename(columns={'teams': 'team'})\n",
    "match_results_df = match_results_df[match_results_df['outcome.method'] != \"D/L\"]\n",
    "\n",
    "# Load the ball-by-ball innings data\n",
    "with open('../data/innings_results.json') as file:\n",
    "    innings_data = json.load(file)\n",
    "\n",
    "innings_df = pd.DataFrame(innings_data)\n",
    "\n",
    "# Remove matches with no result\n",
    "match_results_df = match_results_df[match_results_df['outcome.winner'].notna()]\n",
    "\n",
    "# Get matchids of matches with result\n",
    "match_ids_with_result = match_results_df['matchid'].unique()\n",
    "\n",
    "# Filter innings_df to include only matchids of matches with result\n",
    "innings_df = innings_df[innings_df['matchid'].isin(match_ids_with_result)]\n",
    "\n",
    "# Merge the gender field from match_results_df to innings_df\n",
    "innings_df = innings_df.merge(match_results_df[['matchid', 'team', 'gender', 'dates']], on=['matchid', 'team'], how='left')\n",
    "\n",
    "# Filter for male matches\n",
    "innings_df = innings_df[innings_df['gender'] == 'male']\n",
    "\n",
    "# Convert the 'dates' column to datetime format\n",
    "innings_df['dates'] = pd.to_datetime(innings_df['dates'])\n",
    "\n",
    "# Filter out matches before 2019\n",
    "# innings_df = innings_df[innings_df['dates'].dt.year == 2020]\n",
    "\n",
    "# Keep only necessary columns \n",
    "innings_df = innings_df[['matchid', 'innings', 'over', 'runs.total', 'wicket.kind', 'team']]\n",
    "innings_df = innings_df.drop_duplicates(subset=['matchid', 'innings', 'over', 'team'])\n",
    "# innings_df = innings_df[innings_df['innings'] == 1]\n",
    "\n",
    "# Compute wickets and cumulative wickets directly in innings_df\n",
    "innings_df['wickets'] = innings_df['wicket.kind'].notnull()\n",
    "innings_df['wickets_cumul'] = innings_df.groupby(['matchid', 'innings', 'team'])['wickets'].cumsum()\n",
    "innings_df['runs_cumul'] = innings_df.groupby(['matchid', 'innings', 'team'])['runs.total'].cumsum()\n",
    "assert innings_df['wickets_cumul'].between(0,10).all()\n",
    "# Compute remaining wickets and remaining overs\n",
    "innings_df['over'] = innings_df['over'].apply(lambda x: int(x.split('.')[0]) if int(x.split('.')[1]) == 6 else float(x)).astype(int)\n",
    "innings_df['remaining_wickets'] = 10 - innings_df['wickets_cumul']\n",
    "innings_df['remaining_overs'] = 50 - innings_df['over']\n",
    "\n",
    "# Calculate total runs per match per innings\n",
    "total_runs = innings_df.groupby(['matchid', 'innings'])['runs.total'].sum().reset_index()\n",
    "\n",
    "# Filter to keep only the first innings\n",
    "first_innings_runs = total_runs[total_runs['innings'] == 1]\n",
    "\n",
    "# Rename columns for merging\n",
    "first_innings_runs = first_innings_runs.rename(columns={'runs.total': 'first_innings_runs'})\n",
    "first_innings_runs = first_innings_runs.drop(columns=['innings'])\n",
    "\n",
    "# Merge first_innings_runs into the main dataframe\n",
    "innings_df = innings_df.merge(first_innings_runs, on='matchid', how='left')\n",
    "\n",
    "# Forward fill the NaNs to propagate the first_innings_runs to the second innings\n",
    "innings_df['first_innings_runs'] = innings_df.groupby('matchid')['first_innings_runs'].ffill()\n",
    "\n",
    "# At this point, the 'first_innings_runs' column for the first innings will be its own score, \n",
    "# which is not what we want. We set 'first_innings_runs' to NaN for the first innings:\n",
    "print(innings_df.columns)\n",
    "innings_df.loc[innings_df['innings'] == 1, 'first_innings_runs'] = 0\n",
    "innings_df['runs_needed_to_par'] = innings_df['first_innings_runs'] - innings_df['runs_cumul']\n",
    "innings_df.loc[innings_df['innings'] == 1, 'runs_needed_to_par'] = 0\n",
    "#  Display the dataframe\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "#     display(innings_df)\n",
    "\n",
    "grouped_df = innings_df.groupby(['matchid', 'innings', 'team', 'over']).agg(\n",
    "    runs=('runs.total', 'sum'),\n",
    "    wickets=('wickets', 'sum'),  \n",
    "    remaining_wickets=('remaining_wickets', 'min'),  # minimum remaining wickets in the over\n",
    "    remaining_overs=('remaining_overs', 'min'),  # minimum remaining overs in the over\n",
    "    cumulative_runs=('runs_cumul', 'max'),  # minimum remaining overs in the over\n",
    "    first_innings_runs=('first_innings_runs', 'max'),\n",
    "    runs_needed_to_par=('runs_needed_to_par', 'min')\n",
    ").reset_index()\n",
    "grouped_df = grouped_df.groupby(['matchid', 'innings']).apply(shift_resources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv('../data/intermediate_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "#     display(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3):\n",
    "    display(grouped_df[grouped_df['matchid']==\"1153846\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return all the rows where cumulative wickets are greater than 10\n",
    "anomalies = grouped_df[grouped_df['runs_needed_to_par'] < 0]\n",
    "grouped_df[grouped_df['runs_needed_to_par'] < 0] = 3\n",
    "print(len(grouped_df))\n",
    "# Display these instances\n",
    "print(len(anomalies))\n",
    "display(anomalies)\n",
    "anomaly_details = innings_df[(innings_df['matchid'].isin(anomalies['matchid'])) & \n",
    "                             (innings_df['innings'].isin(anomalies['innings']))]\n",
    "print(anomaly_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert grouped_df['runs'].between(0, 36).all()\n",
    "assert grouped_df['remaining_wickets'].between(0, 10).all()\n",
    "assert grouped_df['remaining_overs'].between(0, 50).all()\n",
    "assert innings_df['wickets'].between(0,6).all()\n",
    "print(min(grouped_df['runs_needed_to_par']), max(grouped_df['runs_needed_to_par']))\n",
    "assert grouped_df['runs_needed_to_par'].between(0,1000*50*6*6).all()\n",
    "assert grouped_df.isnull().sum().all() == 0\n",
    "assert grouped_df.duplicated().sum() == 0\n",
    "# groupd_df = grouped_df[['over', 'remaining_overs', 'remaining_wickets', 'runs']]\n",
    "# assert (grouped_df.sort_values(['matchid', 'innings', 'over'])['remaining_overs'].diff().dropna() <= 0).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the percentage of remaining resources\n",
    "grouped_df['percentage_of_combined_resources'] = (grouped_df['remaining_wickets'] / 10 + grouped_df['remaining_overs'] / 50) / 2 * 100\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a line plot for each value of remaining wickets\n",
    "for wickets in grouped_df['remaining_wickets'].unique():\n",
    "    subset_df = grouped_df[grouped_df['remaining_wickets'] == wickets]\n",
    "    sns.lineplot(x='remaining_overs', y='percentage_of_combined_resources', data=subset_df, label=f'Remaining wickets: {wickets}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Percentage of Combined Resources')\n",
    "plt.title('Remaining Resources vs Remaining Overs for Different Numbers of Wickets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Remaining overs vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 2. Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_wickets\", y=\"runs\")\n",
    "plt.title('Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Remaining overs and Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\", hue=\"remaining_wickets\", palette=\"viridis\")\n",
    "plt.title('Remaining Overs and Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.legend(title='Remaining Wickets')\n",
    "plt.show()\n",
    "\n",
    "# 4. Percentage of combined resources vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=grouped_df, x=\"percentage_of_combined_resources\", y=\"runs\")\n",
    "plt.title('Percentage of Combined Resources vs Runs')\n",
    "plt.xlabel('Percentage of Combined Resources')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots\n",
    "\n",
    "# 1. Remaining overs vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 2. Remaining wickets vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_wickets\", y=\"runs\")\n",
    "plt.title('Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Remaining overs and Remaining wickets vs Runs\n",
    "# For this, we will make a heatmap\n",
    "pivot_table = grouped_df.pivot_table(index='remaining_overs', columns='remaining_wickets', values='runs', aggfunc='mean')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_table, cmap='viridis')\n",
    "plt.title('Remaining Overs and Remaining Wickets vs Runs')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Remaining Overs')\n",
    "plt.show()\n",
    "\n",
    "# 4. Percentage of combined resources vs Runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"percentage_of_combined_resources\", y=\"runs\")\n",
    "plt.title('Percentage of Combined Resources vs Runs')\n",
    "plt.xlabel('Percentage of Combined Resources')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. Line plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 1. Line plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=grouped_df, x=\"remaining_overs\", y=\"remaining_wickets\")\n",
    "plt.title('Remaining Overs vs remaining wickets')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('wickets')\n",
    "plt.show()\n",
    "\n",
    "# 2. Box plots\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=grouped_df, x=\"remaining_overs\", y=\"runs\")\n",
    "plt.title('Remaining Overs vs Runs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Runs')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"runs\")\n",
    "plt.title('Distribution of Runs')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"wickets\")\n",
    "plt.title('Distribution of wickets')\n",
    "plt.xlabel('Wickets')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_wickets\")\n",
    "plt.title('Distribution of remaining wickets')\n",
    "plt.xlabel('remaining wickets')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Histograms\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_overs\")\n",
    "plt.title('Distribution of remaining overs')\n",
    "plt.xlabel('remaining overs')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 4. Heatmaps\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap_data = grouped_df.pivot_table(index='remaining_wickets', columns='remaining_overs', values='runs', aggfunc='mean')\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\")\n",
    "plt.title('Runs by Remaining Overs and Wickets')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Remaining Wickets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram for runs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"runs\", bins=30, kde=True)\n",
    "plt.title('Distribution of Runs')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for remaining overs\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_overs\", bins=30, kde=True)\n",
    "plt.title('Distribution of Remaining Overs')\n",
    "plt.xlabel('Remaining Overs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for remaining wickets\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=grouped_df, x=\"remaining_wickets\", bins=10, kde=True)\n",
    "plt.title('Distribution of Remaining Wickets')\n",
    "plt.xlabel('Remaining Wickets')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(np.array(y_pred - y * grouped_df[\"runs\"].max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= np.array([10, 50])\n",
    "print(max(X[:,0]))\n",
    "print(max(X[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare the data\n",
    "X = np.sqrt(np.array(grouped_df[[\"remaining_overs\", \"remaining_wickets\", \"innings\", \"cumulative_runs\", \"runs_needed_to_par\", \"last_5_overs_mean_runs\"]]))\n",
    "# X = np.sqrt(np.array(grouped_df[[\"remaining_overs\"]]))\n",
    "y = np.array(grouped_df[\"runs\"])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(objective ='reg:squarederror', n_estimators=100, max_depth=7, eta=1, subsample=0.7, colsample_bytree=0.8),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(50, 10), learning_rate_init=0.01, max_iter=1000, random_state=1)\n",
    "}\n",
    "\n",
    "# Loop through the models and train and evaluate each one\n",
    "for model_name, model in models.items():\n",
    "    # Create the pipeline: preprocessor + model\n",
    "    # pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "    #                        ('model', model)])   # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_val = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train) \n",
    "    mse_test = mean_squared_error(y_test, y_pred_val)\n",
    "    r2 = r2_score(y_test, y_pred_val)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"RMSE train: {np.sqrt(mse_train)}\")\n",
    "    print(f\"RMSE test: {np.sqrt(mse_test)}\")\n",
    "    print(f\"R2 score test: {r2}\")\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/cricket_model.pkl']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(models[\"MLP\"], \"../models/cricket_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. \n",
    "More generally and unrelated to cricket or the previous questions, model deployment in a production\n",
    "environment is an important aspect of an engineer’s toolkit. Describe a scalable architecture (a diagram may\n",
    "be helpful) that would be appropriate for deploying a model that predicts frame-level play values into a cloud\n",
    "environment with the following assumptions:\n",
    "• Spatial temporal high frame-rate data (~1 GB per game)\n",
    "• Play-values are predicted at each frame of a game\n",
    "• Delivery of game predictions are expected to be delivered overnight\n",
    "• 500 games per season with 50 games a day\n",
    "• 5 seasons of existing data\n",
    "• Model training resources:\n",
    "– 8 hour runtime with multiple cores (8) and large memory usage\n",
    "• Model prediction resources:\n",
    "– 60 min runtime per game with a single CPU and 4 GB of memory usage\n",
    "List out the services, tooling, and reasoning for the choices of architecture. For example, a LAMP stack could be\n",
    "appropriate for an internal home network webpage on a Raspberry Pi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cricket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
